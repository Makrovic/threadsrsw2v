{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from custom_cleaning import CustomCleaning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning = CustomCleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"books.csv\")\n",
    "\n",
    "df[\"desc_cleaned\"] = [cleaning.clean(desc) for desc in df[\"description\"]]\n",
    "df[\"desc_cleaned\"] = [cleaning.remove_stopword(desc) for desc in df[\"desc_cleaned\"]]\n",
    "df[\"desc_cleaned\"] = [cleaning.stem(desc) for desc in df[\"desc_cleaned\"]]\n",
    "\n",
    "df[\"desc_cleaned\"] = df[\"desc_cleaned\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_model = Word2Vec(\n",
    "    sentences=df[\"desc_cleaned\"],\n",
    "    vector_size=300,\n",
    "    window=5,\n",
    "    workers=4,\n",
    "    epochs=100,\n",
    "    min_count=1,\n",
    "    sg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(synopsis):\n",
    "    vectors = [book_model.wv[word] for word in synopsis if word in book_model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)  # sum of vectors / n\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_vectors = []\n",
    "for desc in df[\"desc_cleaned\"]:\n",
    "    desc_vector = get_vector(desc)\n",
    "    desc_vectors.append(desc_vector)\n",
    "\n",
    "df[\"desc_vector\"] = [vector for vector in desc_vectors if vector is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER BOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"Nyokap memandangi penjuru kamar gue. Dia diam sebentar, tersenyum, lalu bertanya, ‘Kamu takut ya? Makanya belom tidur?’‘Enggak, kenapa harus takut?’‘Ya, siapa tahu rumah baru ini ada hantunya, hiiiiii...,’ kata Nyokap, mencoba menakut-nakuti.‘Enggak takut, Ma,’ jawab gue.‘Kikkikikiki.’ Nyokap mencoba menirukan suara kuntilanak, yang malah terdengar seperti ABG kebanyakan ngisep lem sewaktu hendak photobox. ‘Kikikikikiki.’‘Aku enggak ta—’‘KIKIKIKIKIKIKIKI!’ Nyokap makin menjadi.‘Ma,’ kata gue, ‘kata orang, kalo kita malem-malem niruin ketawa kuntilanak, dia bisa dateng lho.’‘JANGAN NGOMONG GITU, DIKA!’ Nyokap sewot. ‘Kamu durhaka ya nakut-nakutin orang tua kayak gitu! Awas, ya, kamu, Dika!’‘Lah, tadi yang nakut-nakutin siapa, yang ketakutan siapa.’*****Manusia Setengah Salmon adalah kumpulan tulisan komedi Raditya Dika. Sembilan belas bab di dalam bercerita tentang pindah rumah, pindah hubungan keluarga, sampai pindah hati. Simak juga bab berisi tulisan galau, observasi ngawur, dan lelucon singkat khas Raditya Dika.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nyokap', 'pandang', 'penjuru', 'kamar', 'gue', 'diam', 'sebentar', 'senyum', 'takut', 'ya', 'bom', 'tidur', 'takut', 'ya', 'rumah', 'hantu', 'hiiiiii', 'nyokap', 'coba', 'takut', 'nakuti', 'takut', 'ma', 'gue', 'kikkikikiki', 'nyokap', 'coba', 'tiru', 'suara', 'kuntilanak', 'dengar', 'abg', 'banyak', 'ngisep', 'lem', 'photobox', 'kikikikikiki', 'ta', 'kikikikikikikiki', 'nyokap', 'ma', 'gue', 'orang', 'kalo', 'malem', 'malem', 'niruin', 'ketawa', 'kuntilanak', 'dateng', 'lho', 'ngomong', 'gitu', 'dika', 'nyokap', 'sewot', 'durhaka', 'ya', 'nakut', 'nakutin', 'orang', 'tua', 'kayak', 'gitu', 'awas', 'ya', 'dika', 'nakut', 'nakutin', 'takut', 'manusia', 'salmon', 'kumpul', 'tulis', 'komedi', 'raditya', 'dika', 'sembilan', 'belas', 'bab', 'cerita', 'pindah', 'rumah', 'pindah', 'hubung', 'keluarga', 'pindah', 'hati', 'simak', 'bab', 'isi', 'tulis', 'galau', 'observasi', 'ngawur', 'lelucon', 'singkat', 'khas', 'raditya', 'dika']\n"
     ]
    }
   ],
   "source": [
    "desc_cleaned = cleaning.clean(description)\n",
    "desc_cleaned = cleaning.remove_stopword(desc_cleaned)\n",
    "desc_cleaned = cleaning.stem(desc_cleaned)\n",
    "desc_processed = desc_cleaned.split()\n",
    "\n",
    "print(desc_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query_vector = get_vector(desc_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECOMMEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frekuensi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nyokap</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takut</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ya</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dika</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gue</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pindah</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumah</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coba</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ma</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kuntilanak</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            frekuensi\n",
       "token                \n",
       "nyokap              5\n",
       "takut               5\n",
       "ya                  4\n",
       "dika                4\n",
       "gue                 3\n",
       "pindah              3\n",
       "rumah               2\n",
       "coba                2\n",
       "ma                  2\n",
       "kuntilanak          2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = Counter(desc_processed)\n",
    "most_common_words = word_counts.most_common(10)\n",
    "\n",
    "data_dicts = [{'token': row[0], 'frekuensi': row[1]} for row in most_common_words]\n",
    "freq_df = pd.DataFrame(data_dicts)\n",
    "\n",
    "freq_df.set_index('token', inplace=True)\n",
    "\n",
    "freq_df\n",
    "\n",
    "# for word, count in most_common_words:\n",
    "#     print(f\"{word}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Manusia Setengah Salmon (Paperback)</td>\n",
       "      <td>Nyokap memandangi penjuru kamar gue. Dia diam ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Watir (Paperback)</td>\n",
       "      <td>Banyak anak zaman sekarang yang gampang galau....</td>\n",
       "      <td>0.874157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Poconggg Juga Pocong (Paperback)</td>\n",
       "      <td>Predikat sebagai pocong jantan tinggal sedikit...</td>\n",
       "      <td>0.859139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Rahasia Pesan Serigala (Kelompok 2&amp;amp;1 #6)</td>\n",
       "      <td>HOMO HOMINI LUPUS.\"Jadi... jadi... kaukah oran...</td>\n",
       "      <td>0.856259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Marriagable: Gue Mau Nikah Asal... (Paperback)</td>\n",
       "      <td>Namaku Flory. Usia mendekati tiga puluh dua. S...</td>\n",
       "      <td>0.854566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Trust No One, Suspect Everyone!: My Stupid Bos...</td>\n",
       "      <td>“This is the funniest book I have ever read. S...</td>\n",
       "      <td>0.851175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "80                  Manusia Setengah Salmon (Paperback)   \n",
       "644                                   Watir (Paperback)   \n",
       "256                    Poconggg Juga Pocong (Paperback)   \n",
       "1003       Rahasia Pesan Serigala (Kelompok 2&amp;1 #6)   \n",
       "422      Marriagable: Gue Mau Nikah Asal... (Paperback)   \n",
       "408   Trust No One, Suspect Everyone!: My Stupid Bos...   \n",
       "\n",
       "                                            description  similarity_score  \n",
       "80    Nyokap memandangi penjuru kamar gue. Dia diam ...          1.000000  \n",
       "644   Banyak anak zaman sekarang yang gampang galau....          0.874157  \n",
       "256   Predikat sebagai pocong jantan tinggal sedikit...          0.859139  \n",
       "1003  HOMO HOMINI LUPUS.\"Jadi... jadi... kaukah oran...          0.856259  \n",
       "422   Namaku Flory. Usia mendekati tiga puluh dua. S...          0.854566  \n",
       "408   “This is the funniest book I have ever read. S...          0.851175  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores = cosine_similarity([user_query_vector], df[\"desc_vector\"].tolist())[0]\n",
    "similar_indices = similarity_scores.argsort()[-6:][::-1]\n",
    "\n",
    "similar_books = df.loc[\n",
    "    similar_indices,\n",
    "    [\"title\", \"description\"],\n",
    "]\n",
    "similar_books[\"similarity_score\"] = similarity_scores[similar_indices]\n",
    "similar_books"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from custom_cleaning import CustomCleaning\n",
    "from threads import Threads\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "threadsnet = Threads()\n",
    "cleaning = CustomCleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"books.csv\")\n",
    "\n",
    "df[\"desc_cleaned\"] = [cleaning.clean(desc) for desc in df[\"description\"]]\n",
    "df[\"desc_cleaned\"] = [cleaning.remove_stopword(desc) for desc in df[\"desc_cleaned\"]]\n",
    "df[\"desc_cleaned\"] = [cleaning.stem(desc) for desc in df[\"desc_cleaned\"]]\n",
    "\n",
    "df[\"desc_cleaned\"] = df[\"desc_cleaned\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_model = Word2Vec(\n",
    "    sentences=df[\"desc_cleaned\"],\n",
    "    vector_size=300,\n",
    "    window=5,\n",
    "    workers=4,\n",
    "    epochs=100,\n",
    "    sg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(synopsis):\n",
    "    vectors = [book_model.wv[word] for word in synopsis if word in book_model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)  # sum of vectors / n\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_vectors = []\n",
    "for desc in df[\"desc_cleaned\"]:\n",
    "    desc_vector = get_vector(desc)\n",
    "    desc_vectors.append(desc_vector)\n",
    "\n",
    "df[\"desc_vector\"] = [vector for vector in desc_vectors if vector is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'salimafillah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = threadsnet.public_api.get_user_id(username)\n",
    "user_threads = threadsnet.public_api.get_user_threads(user_id)\n",
    "threads = user_threads[\"data\"][\"mediaData\"][\"threads\"]\n",
    "\n",
    "user_caption = []\n",
    "for thread in threads:\n",
    "    if thread[\"thread_items\"][0][\"post\"][\"caption\"] is not None:\n",
    "        text = thread[\"thread_items\"][0][\"post\"][\"caption\"][\"text\"]\n",
    "        text = cleaning.clean(text)  # clean sentence from unnecessary characters\n",
    "        text = cleaning.remove_stopword(text)  # remove stopwords from sentence\n",
    "        text = cleaning.stem(text)  # stem\n",
    "        user_caption.append(text)\n",
    "\n",
    "user_sent = \" \".join(user_caption)\n",
    "\n",
    "user_sent_processed = user_sent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query_vector = get_vector(user_sent_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECOMMEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frekuensi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allah</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nikmat</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jumat</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jamin</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doa</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>threads</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iman</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kau</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tangan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dekat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  frekuensi\n",
       "0    allah          9\n",
       "1   nikmat          4\n",
       "2    jumat          4\n",
       "3    jamin          3\n",
       "4      doa          3\n",
       "5  threads          2\n",
       "6     iman          2\n",
       "7      kau          2\n",
       "8   tangan          2\n",
       "9    dekat          2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = Counter(user_sent_processed)\n",
    "most_common_words = word_counts.most_common(10)\n",
    "\n",
    "data_dicts = [{'token': row[0], 'frekuensi': row[1]} for row in most_common_words]\n",
    "freq_df = pd.DataFrame(data_dicts)\n",
    "\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Jalan Bandungan (Paperback)</td>\n",
       "      <td>0.921188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Tak Ada Santo dari Sirkus (Paperback)</td>\n",
       "      <td>0.919571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Berjuta Rasanya (Paperback)</td>\n",
       "      <td>0.913615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Kereta Tidur (Paperback)</td>\n",
       "      <td>0.913129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laskar Pelangi (Paperback)</td>\n",
       "      <td>0.910859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Supernova: Akar (Paperback)</td>\n",
       "      <td>0.906417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Muslihat Musang Emas (Paperback)</td>\n",
       "      <td>0.905741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Kekasih Marionette dan 12 Kisah Lainnya (Paper...</td>\n",
       "      <td>0.905566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>Haduh, aku di-follow (Paperback)</td>\n",
       "      <td>0.905312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>Jingga (Paperback)</td>\n",
       "      <td>0.903698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  similarity_score\n",
       "375                        Jalan Bandungan (Paperback)          0.921188\n",
       "661              Tak Ada Santo dari Sirkus (Paperback)          0.919571\n",
       "211                        Berjuta Rasanya (Paperback)          0.913615\n",
       "988                           Kereta Tidur (Paperback)          0.913129\n",
       "3                           Laskar Pelangi (Paperback)          0.910859\n",
       "8                          Supernova: Akar (Paperback)          0.906417\n",
       "66                    Muslihat Musang Emas (Paperback)          0.905741\n",
       "382  Kekasih Marionette dan 12 Kisah Lainnya (Paper...          0.905566\n",
       "925                   Haduh, aku di-follow (Paperback)          0.905312\n",
       "713                                 Jingga (Paperback)          0.903698"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores = cosine_similarity([user_query_vector], df[\"desc_vector\"].tolist())[0]\n",
    "similar_indices = similarity_scores.argsort()[-10:][::-1]\n",
    "\n",
    "similar_books = df.loc[\n",
    "    similar_indices,\n",
    "    [\"title\"],\n",
    "]\n",
    "similar_books[\"similarity_score\"] = similarity_scores[similar_indices]\n",
    "similar_books"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
